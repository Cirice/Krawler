# KRAWLER: A WEB CRAWLER IN PYTHON3

It's a simple multithreaded web crawler wich downloads and stores web pages.

[![GitHub issues](https://img.shields.io/github/issues/habedi/Krawler.svg?style=plastic)](https://github.com/habedi/Krawler/issues)	[![GitHub forks](https://img.shields.io/github/forks/habedi/Krawler.svg?style=plastic)](https://github.com/habedi/Krawler/network)	[![GitHub stars](https://img.shields.io/github/stars/habedi/Krawler.svg?style=plastic)](https://github.com/habedi/Krawler/stargazers)	[![GitHub license](https://img.shields.io/badge/license-AGPL-blue.svg?style=plastic)](https://raw.githubusercontent.com/habedi/Krawler/master/LICENSE)

Project Source code:
---
	See inside src/*

Project docs:
---
	See inside docs/*

Installing the system-wide dependencies:
---
    $ bash system-dependencies.sh
    $ sudo pip3 install -U -r requirements.txt

Starting the crawler:
---
	$ pushd src; python3 main.py; popd
	
![Web Search Engine](docs/figures//WebCrawlerArchitecture.png "Web Search Engine's Architecture")
